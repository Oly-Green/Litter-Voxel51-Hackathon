{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {'glass': [9, 26], 'plastic': [29, 42, 47, 48, 49], 'paper': [33, 35], 'styrofoam': [57]}\n",
    "class_to_category_idx = {9: 0, 26: 0, 29: 3, 42: 3, 47: 3, 48: 3, 49: 3, 33: 1, 35: 1, 57: 2}\n",
    "idx_to_category = {0: 'glass', 1: 'paper', 2: 'styrofoam', 3: 'plastic', 4: 'other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TacoTrashDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, isTrain=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.isTrain = isTrain\n",
    "\n",
    "        with open(data_dir + '/annotations.json') as f:\n",
    "            self.data_info = json.load(f)\n",
    "        \n",
    "        self.images_info = self.data_info['images']\n",
    "        self.annotation_info = self.data_info['annotations']\n",
    "\n",
    "        # self.restrictAnnotations()\n",
    "        self.splitTrainTest()\n",
    "    \n",
    "    def restrictAnnotations(self):\n",
    "        self.annotation_info  = []\n",
    "        for annotation in self.all_annotation_info:\n",
    "            if annotation['category_id'] in [9, 26, 29, 42, 47, 48, 49, 33, 35, 57]:\n",
    "                self.annotation_info.append(annotation)\n",
    "    \n",
    "    def splitTrainTest(self):\n",
    "        random.shuffle(self.annotation_info)\n",
    "        self.train_annotation_info = self.annotation_info[:int(0.8*len(self.annotation_info))]\n",
    "        self.test_annotation_info = self.annotation_info[int(0.8*len(self.annotation_info)):]\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.isTrain:\n",
    "            return len(self.train_annotation_info)\n",
    "        else:\n",
    "            return len(self.test_annotation_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTrain:\n",
    "            annotation = self.train_annotation_info[idx]\n",
    "        else:            \n",
    "            annotation = self.test_annotation_info[idx]\n",
    "        \n",
    "        img_idx = annotation['image_id']\n",
    "        img_path = os.path.join(self.data_dir, self.images_info[img_idx]['file_name'])\n",
    "        if annotation['category_id'] in [9, 26, 29, 42, 47, 48, 49, 33, 35, 57]:\n",
    "            label = class_to_category_idx[annotation['category_id']]\n",
    "        else:\n",
    "            label = 4\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        bbox = annotation['bbox']\n",
    "        image = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "        labels = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TacoTrashDataset(\n",
    "    data_dir='D:/Work/My Projects/LitterDetection/Litter-Voxel51-Hackathon/TACO/data',\n",
    "    transform=transform,\n",
    "    isTrain=True\n",
    ")\n",
    "test_dataset = TacoTrashDataset(\n",
    "    data_dir='D:/Work/My Projects/LitterDetection/Litter-Voxel51-Hackathon/TACO/data',\n",
    "    transform=transform,\n",
    "    isTrain=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrav\\anaconda3\\envs\\hackathon\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shrav\\anaconda3\\envs\\hackathon\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "num_custom_classes = 5\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_custom_classes)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0017, Accuracy: 0.00%\n",
      "Validation Loss: 0.0059, Validation Accuracy: 25.00%\n",
      "Epoch 2/10, Loss: 0.0017, Accuracy: 0.00%\n",
      "Validation Loss: 0.0055, Validation Accuracy: 50.00%\n",
      "Epoch 3/10, Loss: 0.0016, Accuracy: 75.00%\n",
      "Validation Loss: 0.0054, Validation Accuracy: 75.00%\n",
      "Epoch 4/10, Loss: 0.0014, Accuracy: 100.00%\n",
      "Validation Loss: 0.0056, Validation Accuracy: 75.00%\n",
      "Epoch 5/10, Loss: 0.0012, Accuracy: 100.00%\n",
      "Validation Loss: 0.0039, Validation Accuracy: 100.00%\n",
      "Epoch 6/10, Loss: 0.0013, Accuracy: 75.00%\n",
      "Validation Loss: 0.0041, Validation Accuracy: 100.00%\n",
      "Epoch 7/10, Loss: 0.0013, Accuracy: 75.00%\n",
      "Validation Loss: 0.0033, Validation Accuracy: 100.00%\n",
      "Epoch 8/10, Loss: 0.0009, Accuracy: 100.00%\n",
      "Validation Loss: 0.0057, Validation Accuracy: 50.00%\n",
      "Epoch 9/10, Loss: 0.0008, Accuracy: 100.00%\n",
      "Validation Loss: 0.0035, Validation Accuracy: 75.00%\n",
      "Epoch 10/10, Loss: 0.0011, Accuracy: 75.00%\n",
      "Validation Loss: 0.0042, Validation Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(test_dataloader.dataset)\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
